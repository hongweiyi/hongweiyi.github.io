<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> MapReduce优化（二） —— 善用Writable · 小e的笔记</title><meta name="description" content="一、简述
上文主要是数据压缩的角度来分析了MapReduce压缩临时数据的优化，参见：MapReduce优化（一）。而这篇会更多的从代码层面说MR任务优化。
MapReduce大多数任务都是做日志分析，而一般的日志分析也就是高级点的WordCount程序：读入一段文本 -&amp;gt; 获取需要的信息 -&amp;gt; 统计输出。  
我这里的任务会从SequenceFile中读取文档（每个文档4M），每条文档里面有许多行记录，每个记录有一个词和词频。任务需要统计记录中所有词出现的绝对频率以及文档频率。格式如下：                              word1 freq1\n
word2 freq2\n
word3 freq3\n        "><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="stylesheet" href="http://fonts.useso.com/css?family=Source+Sans+Pro:400,600" type="text/css"></head><body><header><a href="/" class="logo-link"><img src="/favicon.png"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="http://weibo.com/1674333040" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="https://twitter.com/hongwei89" target="_blank" class="nav-list-link">TWITTER</a></li><li class="nav-list-item"><a href="/archives" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">MapReduce优化（二） —— 善用Writable</h1><div class="post-meta"><div class="post-time">Sep 27, 2012 | [<a class="tag-link" href="/tags/Hadoop/">Hadoop</a>, <a class="tag-link" href="/tags/MapReduce/">MapReduce</a>]</div></div><div class="post-content"><p><strong>一、简述</strong></p>
<p>上文主要是数据压缩的角度来分析了MapReduce压缩临时数据的优化，参见：<a href="http://www.hongweiyi.com/2012/02/mapred-optimize/" target="_blank" rel="external">MapReduce优化（一）</a>。而这篇会更多的从代码层面说MR任务优化。</p>
<p>MapReduce大多数任务都是做日志分析，而一般的日志分析也就是高级点的WordCount程序：读入一段文本 -&gt; 获取需要的信息 -&gt; 统计输出。<br><a id="more"></a>  </p>
<p>我这里的任务会从SequenceFile中读取文档（每个文档4M），每条文档里面有许多行记录，每个记录有一个词和词频。任务需要统计记录中所有词出现的绝对频率以及文档频率。格式如下：   <table border="1" cellspacing="0" cellpadding="0"><tbody>       <tr>         <td valign="top" width="568">           <p>word1 freq1\n</p>
<p>word2 freq2\n</p>
<p>word3 freq3\n<br>         </p></td>       </tr>     </tbody></table> </p>  <p></p>
<p><strong>二、善用**</strong>Writable**</p>
<p>程序逻辑应该是这样的：</p>
<p>1）根据换行符分隔文档；</p>
<p>2）读取每一行数据；</p>
<p>3）并输出绝对频率(word, freq)与文档频率(word, ONE)两条记录。</p>
<p>简单明了的程序处理方式应该是这样的：   <table border="1" cellspacing="0" cellpadding="0"><tbody>       <tr>         <td valign="top" width="568">           <p>1. String str = value.toString(); </p>
<p>2. String[] ln = str.split(&quot;\n&quot;); </p>
<p>3. for(String l : ln) {</p>
<p>4.&#160;&#160;&#160;&#160; String[] words = ln.split(&quot; &quot;);</p>
<p>5.&#160;&#160;&#160;&#160; context.write(new Text(words[0]), new LongWritable(1));</p>
<p>6.&#160;&#160;&#160;&#160; context.write(new Text(words[0]), new LongWritable(Long.parseLong(words[1]));</p>
<p>7. }<br>         </p></td>       </tr>     </tbody></table> </p>  <p></p>
<p>上面代码可优化的地方有三：</p>
<p>1）在1行代码中，value的toString方法会对数据进行decode，decode效率很慢。而且该方法会分配内存空间；</p>
<p>2）在2行代码中，和split(&quot;\n&quot;)效率低下；</p>
<p>3）5和6行中，每次都会“新”创建“两对”Text，LongWritable对象，GC频繁。</p>
<p>在上面的问题中，问题1和问题2可以一起解决，避免decode和分配内存就需要直接处理byte数组重写Text这个Writable类。只需要继承Text类并添加nextLine()方法即可。添加nextLine()方法是为了逻辑清晰，如果为了更高的效率的话，可以添加nextWord()与nextFreq()方法。</p>
<p>问题3比较常见，在很多资料以及Hadoop自带的Example里面可以看到，输出的键值对均是复用的。用一个全局的KEY和VALUE，直接将新数据set进KEY、VALUE中即可，无需每次新创建相应对象。上面还有一个小地方可以优化的就是，将LongWritable改为IntWritable，减少数据输出。</p>
<p>上面的解决方案似乎还不错了，但是map输出的临时数据依然很大。回查代码，发现context.write()数据太多了，最后的解决方案是将文档频率和绝对频率合并起来，简单点的格式就是：d_freq#freq。这样临时数据一下就减少了一半。</p>
<p>以下是修改后的代码流程：   <table border="1" cellspacing="0" cellpadding="0"><tbody>       <tr>         <td valign="top" width="568">           <p>1. while (value.hasNext()) {</p>
<p>2.&#160;&#160;&#160;&#160; KEY.set(value.nextWord());</p>
<p>3.&#160;&#160;&#160;&#160; VALUE.set(&quot;1#&quot; + value.nextFreq());</p>
<p>4.&#160;&#160;&#160;&#160; context.write(KEY, VALUE);</p>
<p>5. }<br>         </p></td>       </tr>     </tbody></table> </p>  <p></p>
<p><strong>三、优化结果</strong></p>
<p>通过上面的优化，处理300G的数据，单个map task平均时间从3’30’’降到45’’，FILE_BYTE_WRITEN从1000G降到了450G，任务总时间从4小时降到了30分钟。</p>
<p>P.S.: 20台节点。</p>
<p><strong>四、后记</strong></p>
<p>后来我在这个任务里面使用了Gzip压缩，压缩率约为44%。但是对效率的影响太大了，单个map task平均时间从45’’升到1’20’’，打了一半的折扣，着实让人难以接受。由于对集群没有完全的管理权限，所以无法在这个任务上面尝试Lzo压缩编码，有机会在尝试吧。</p>
</div></article></div></section><footer><div class="paginator"><a href="/2012/10/mapreduce-task-src-analysis/" class="prev">上一篇</a><a href="/2012/09/hadoop-bug-in-text/" class="next">下一篇</a></div><div data-thread-key="2012/09/mapred-optimize-writable/" data-title="MapReduce优化（二） —— 善用Writable" data-url="http://hongweiyi.com/2012/09/mapred-optimize-writable/" data-author-key="1" class="ds-thread"></div><script>var duoshuoQuery = {short_name:"yihongwei"};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
})();

</script></footer><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-66911097-1",'auto');ga('send','pageview');</script><script src="https://cdn.bootcss.com/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>