<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Hadoop默认配置和常用配置 · 小e的笔记</title><meta name="description" content="获取默认配置
配置hadoop，主要是配置core-site.xml，hdfs-site.xml，mapred-site.xml三个配置文件，默认下来，这些配置文件都是空的，所以很难知道这些配置文件有哪些配置可以生效，上网找的配置可能因为各个hadoop版本不同，导致无法生效。浏览更多的配置，有两个方法：
1.选择相应版本的hadoop，下载解压后，找到core-default.xml，hdfs-default.xml，mapred-default.xml。这些分别在hadoop/src/{core | hdfs | mapred}下面。这些就是默认配置，可以参考这些配置的说明和key，配置hadoop集群。

2.浏览apache官网，三个配置文件链接如下：
http://hadoop.apache.org/common/docs/r0.20.2/core-default.html
&lt;a href=&quot;http://hadoop"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="stylesheet" href="http://fonts.useso.com/css?family=Source+Sans+Pro:400,600" type="text/css"></head><body><header><a href="/" class="logo-link"><img src="/favicon.png"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="http://weibo.com/1674333040" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="https://twitter.com/hongwei89" target="_blank" class="nav-list-link">TWITTER</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li><li class="nav-list-item"><a href="/tags" target="_self" class="nav-list-link">TAGS</a></li></ul></header><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">Hadoop默认配置和常用配置</h1><div class="post-meta"><div class="post-time">Apr 20, 2012</div></div><div class="post-content"><p><strong>获取默认配置</strong></p>
<p>配置hadoop，主要是配置core-site.xml，hdfs-site.xml，mapred-site.xml三个配置文件，默认下来，这些配置文件都是空的，所以很难知道这些配置文件有哪些配置可以生效，上网找的配置可能因为各个hadoop版本不同，导致无法生效。浏览更多的配置，有两个方法：</p>
<p>1.选择相应版本的hadoop，下载解压后，找到core-default.xml，hdfs-default.xml，mapred-default.xml。这些分别在hadoop/src/{core | hdfs | mapred}下面。这些就是默认配置，可以参考这些配置的说明和key，配置hadoop集群。</p>
<a id="more"></a>
<p>2.浏览apache官网，三个配置文件链接如下：</p>
<p><a href="http://hadoop.apache.org/common/docs/r0.20.2/core-default.html" target="_blank" rel="external">http://hadoop.apache.org/common/docs/r0.20.2/core-default.html</a></p>
<p><a href="http://hadoop.apache.org/common/docs/r0.20.2/hdfs-default.html" target="_blank" rel="external">http://hadoop.apache.org/common/docs/r0.20.2/hdfs-default.html</a></p>
<p><a href="http://hadoop.apache.org/common/docs/r0.20.2/mapred-default.html" target="_blank" rel="external">http://hadoop.apache.org/common/docs/r0.20.2/mapred-default.html</a></p>
<p>这里是浏览hadoop当前版本号的默认配置文件，其他版本号，要另外去官网找。其中第一个方法找到默认的配置是最好的，因为每个属性都有说明，可以直接使用。另外，core-site.xml是全局配置，hdfs-site.xml和mapred-site.xml分别是hdfs和mapred的局部配置。</p>
<p><strong>常用的端口配置</strong></p>
<p><strong>HDFS**</strong>端口**</p>
<p><table border="1" cellspacing="0" cellpadding="0"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td><strong>参数</strong></td></p>
<p><td><strong>描述</strong></td></p>
<p><td><strong>默认</strong></td></p>
<p><td><strong>例子值</strong></td><br></p>
<p><tr></tr></p>
<p><td>fs.default.name</td></p>
<p><td>namenode RPC交互端口</td></p>
<p><td>8020</td></p>
<p><td>hdfs：//master：8020/</td><br></p>
<p><tr></tr></p>
<p><td>dfs.http.address</td></p>
<p><td>NameNode web管理端口</td></p>
<p><td>50070</td></p>
<p><td>0.0.0.0：50070</td><br></p>
<p><tr></tr></p>
<p><td>dfs.datanode.address</td></p>
<p><td>datanode 控制端口</td></p>
<p><td>50010</td></p>
<p><td>0.0.0.0：50010</td><br></p>
<p><tr></tr></p>
<p><td>dfs.datanode.ipc.address</td></p>
<p><td>datanode的RPC服务器地址和端口</td></p>
<p><td>50020</td></p>
<p><td>0.0.0.0：50020</td><br></p>
<p><tr></tr></p>
<p><td>dfs.datanode.http.address</td></p>
<p><td>datanode的HTTP服务器和端口</td></p>
<p><td>50075</td></p>
<p><td>0.0.0.0：50075</td><br><br><br><br><strong>MR**</strong>端口**</p>
<p><table border="1" cellspacing="0" cellpadding="0"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td><strong>参数</strong></td></p>
<p><td><strong>描述</strong></td></p>
<p><td><strong>默认</strong></td></p>
<p><td><strong>例子值</strong></td><br></p>
<p><tr></tr></p>
<p><td>mapred.job.tracker</td></p>
<p><td>job tracker交互端口</td></p>
<p><td>8021</td></p>
<p><td>hdfs：//master：8021/</td><br></p>
<p><tr></tr></p>
<p><td>mapred.job.tracker.http.address</td></p>
<p><td>job tracker的web管理端口</td></p>
<p><td>50030</td></p>
<p><td>0.0.0.0：50030</td><br></p>
<p><tr></tr></p>
<p><td>mapred.task.tracker.http.address</td></p>
<p><td>task tracker的HTTP端口</td></p>
<p><td>50060</td></p>
<p><td>0.0.0.0：50060</td><br><br><br><br><strong>其他端口</strong></p>
<p><table border="1" cellspacing="0" cellpadding="0"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td><strong>参数</strong></td></p>
<p><td><strong>描述 </strong></td></p>
<p><td><strong>默认 </strong></td></p>
<p><td><strong>例子值</strong></td><br></p>
<p><tr></tr></p>
<p><td>dfs.secondary.http.address</td></p>
<p><td>secondary NameNode web管理端口</td></p>
<p><td>50090</td></p>
<p><td>0.0.0.0：28680</td><br><br><br><br><strong>集群目录配置</strong></p>
<p><table border="1" cellspacing="0" cellpadding="0"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td><strong>参数</strong></td></p>
<p><td><strong>描述 </strong></td></p>
<p><td><strong>默认 </strong></td></p>
<p><td><strong>例子值</strong></td><br></p>
<p><tr></tr></p>
<p><td>dfs.name.dir</td></p>
<p><td>name node的元数据，以，号隔开，hdfs会把元数据冗余复制到这些目录，一般这些目录是不同的块设备，不存在的目录会被忽略掉</td></p>
<p><td>{hadoop.tmp.dir}</td></p>
<p>/dfs/name</p>
<p><td>/hadoop/hdfs/name</td><br></p>
<p><tr></tr></p>
<p><td>dfs.name.edits.dir</td></p>
<p><td>node node的事务文件存储的目录，以，号隔开，hdfs会把事务文件冗余复制到这些目录，一般这些目录是不同的块设备，不存在的目录会被忽略掉</td></p>
<p><td>${dfs.name.dir}</td></p>
<p><td>${dfs.name.dir}</td><br></p>
<p><tr></tr></p>
<p><td>fs.checkpoint.dir</td></p>
<p><td>secondary NameNode的元数据以，号隔开，hdfs会把元数据冗余复制到这些目录，一般这些目录是不同的块设备，不存在的目录会被忽略掉</td></p>
<p><td>${hadoop.tmp.dir}</td></p>
<p>/dfs/namesecondary</p>
<p><td>/hadoop/hdfs/</td></p>
<p>namesecondary<br></p>
<p><tr></tr></p>
<p><td>fs.checkpoint.edits</td></p>
<p>.dir</p>
<p><td>secondary NameNode的事务文件存储的目录，以，号隔开，hdfs会把事务文件冗余复制到这些目录</td></p>
<p><td>${fs.checkpoint.dir}</td></p>
<p><td>${fs.checkpoint.dir}</td><br></p>
<p><tr></tr></p>
<p><td>hadoop.tmp.dir</td></p>
<p><td>临时目录，其他临时目录的父目录</td></p>
<p><td>/tmp/hadoop-${user.name}</td></p>
<p><td>/hadoop/tmp/hadoop-</td></p>
<p>${user.name}<br></p>
<p><tr></tr></p>
<p><td>dfs.data.dir</td></p>
<p><td>data node的数据目录，以，号隔开，hdfs会把数据存在这些目录下，一般这些目录是不同的块设备，不存在的目录会被忽略掉</td></p>
<p><td>${hadoop.tmp.dir}</td></p>
<p>/dfs/data</p>
<p><td>/hadoop/hdfs/data1/data</td></p>
<p>/hadoop/hdfs/data2/data<br></p>
<p><tr></tr></p>
<p><td>mapred.local.dir</td></p>
<p><td>MapReduce产生的中间数据存放目录，以，号隔开，hdfs会把数据存在这些目录下，一般这些目录是不同的块设备，不存在的目录会被忽略掉</td></p>
<p><td>${hadoop.tmp.dir}</td></p>
<p>/mapred/local</p>
<p><td>/hadoop/hdfs/data1/</td></p>
<p>mapred/local</p>
<p>/hadoop/hdfs/data2/</p>
<p>mapred/local<br></p>
<p><tr></tr></p>
<p><td>mapred.system.dir</td></p>
<p><td>MapReduce的控制文件</td></p>
<p><td>${hadoop.tmp.dir}</td></p>
<p>/mapred/system</p>
<p><td>/hadoop/hdfs/data1/system</td><br><br><br><br><strong>其他配置</strong></p>
<p><table border="1" cellspacing="0" cellpadding="0"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td><strong>参数</strong></td></p>
<p><td><strong>描述 </strong></td></p>
<p><td><strong>默认 </strong></td></p>
<p><td><strong>例子值</strong></td><br></p>
<p><tr></tr></p>
<p><td>dfs.support.append</td></p>
<p><td>支持文件append，主要是支持hbase</td></p>
<p><td>false</td></p>
<p><td>true</td><br></p>
<p><tr></tr></p>
<p><td>dfs.replication</td></p>
<p><td>文件复制的副本数，如果创建时不指定这个参数，就使用这个默认值作为复制的副本数</td></p>
<p><td>3</td></p>
<p><td>2</td><br><br><br><br>&nbsp;</p>
<blockquote>
<p>转载：</p>
<p><a href="http://www.cnblogs.com/ggjucheng/archive/2012/04/17/2454590.html" target="_blank" rel="external">http://www.cnblogs.com/ggjucheng/archive/2012/04/17/2454590.html</a></p>
</blockquote>
</div></article></div></section><footer><div class="paginator"><a href="/2012/04/relax-schrodinger-cat/" class="prev">上一篇</a><a href="/2012/04/nlp-say-hi/" class="next">下一篇</a></div><div data-thread-key="2012/04/hadoop-default-conf/" data-title="Hadoop默认配置和常用配置" data-url="http://hongweiyi.com/2012/04/hadoop-default-conf/" data-author-key="1" class="ds-thread"></div><script>var duoshuoQuery = {short_name:"yihongwei"};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
})();

</script></footer><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-66911097-1",'auto');ga('send','pageview');</script><script src="https://cdn.bootcss.com/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>