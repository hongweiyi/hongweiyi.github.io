<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 迭代式MapReduce解决方案（二） DistributedCache · 小e的笔记</title><meta name="description" content="1、DistributedCache In Hadoop此篇文章主要是前一篇的后续，主要讲Hadoop的分布式缓存机制的原理与运用。
分布式缓存在MapReduce中称之为DistributedCache，它可以方便map task之间或者reduce task之间共享一些信息，同时也可以将第三方包添加到其classpath路径中去。Hadoop会将缓存数据分发到集群的所有准备启动的节点上，复制到在mapred.temp.dir中配置的目录。
   
2、DistributedCache的使用DistributedCache的使用的本质其实是添加Configuraton中的属性：mapred.cache.{files|archives}。图方便的话，可以使用DistributedCache类的静态方法。
不省事法：
&lt;tab"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="stylesheet" href="http://fonts.useso.com/css?family=Source+Sans+Pro:400,600" type="text/css"></head><body><header><a href="/" class="logo-link"><img src="/favicon.png"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="http://weibo.com/1674333040" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="https://twitter.com/hongwei89" target="_blank" class="nav-list-link">TWITTER</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li><li class="nav-list-item"><a href="/tags" target="_self" class="nav-list-link">TAGS</a></li></ul></header><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">迭代式MapReduce解决方案（二） DistributedCache</h1><div class="post-meta"><div class="post-time">Feb 23, 2012</div></div><div class="post-content"><h3 id="1、DistributedCache_In_Hadoop">1、DistributedCache In Hadoop</h3><p>此篇文章主要是<a href="http://www.hongweiyi.com/?p=250" target="_blank" rel="external">前一篇</a>的后续，主要讲Hadoop的分布式缓存机制的原理与运用。</p>
<p>分布式缓存在MapReduce中称之为DistributedCache，它可以方便map task之间或者reduce task之间共享一些信息，同时也可以将第三方包添加到其classpath路径中去。Hadoop会将缓存数据分发到集群的所有准备启动的节点上，复制到在mapred.temp.dir中配置的目录。</p>
 <a id="more"></a>  
<h3 id="2、DistributedCache的使用">2、DistributedCache的使用</h3><p>DistributedCache的使用的本质其实是添加Configuraton中的属性：mapred.cache.{files|archives}。图方便的话，可以使用DistributedCache类的静态方法。</p>
<p>不省事法：</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">conf</span>.<span class="keyword">set</span>(<span class="string">"mapred.cache.files"</span>, <span class="string">"/data/data"</span>);</span><br><span class="line"><span class="keyword">conf</span>.<span class="keyword">set</span>(<span class="string">"mapred.cache. archives"</span>, <span class="string">"/data/data.zip"</span>);</span><br></pre></td></tr></table></figure>
<p>省事法：</p>
<ul>
<li><a href="http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/filecache/DistributedCache.html" target="_blank" rel="external">DistributedCache</a>. <code>**[addCacheFile](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/filecache/DistributedCache.html#addCacheFile(java.net.URI, org.apache.hadoop.conf.Configuration))**``([URI](http://java.sun.com/javase/6/docs/api/java/net/URI.html?is-external=true),</code> <code>[Configuration](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/conf/Configuration.html))</code></li>
<li><a href="http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/filecache/DistributedCache.html" target="_blank" rel="external">DistributedCache</a>.<code>**[addArchiveToClassPath](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/filecache/DistributedCache.html#addArchiveToClassPath(org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem))**``([Path](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/fs/Path.html),</code> <code>[Configuration](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/conf/Configuration.html),</code> <code>[FileSystem](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/fs/FileSystem.html))</code></li>
</ul>
<p>需要注意的是，上面几行代码需要写在Job类初始化之前，否则在运行会中找不到文件（被折磨了很长时间），因为Job初始化时将传入Configuration对象克隆一份给了JobContext。</p>
<p>在MapReduce的0.21版本以后的org.apache.hadoop.mapreduce均移到org.apache.hadoop.mapred包下。但文档中提供的configure方法是重写的MapReduceBase中的，而新版本中map继承于mapper，reduce继承于reducer，所以configure方法一律改成了setup。要获得cache数据，就得在map/reduce task中的setup方法中取得cache数据，再进行相应操作：  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="annotation">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException,  </span><br><span class="line">        InterruptedException </span>&#123;  </span><br><span class="line">    <span class="keyword">super</span>.setup(context);  </span><br><span class="line">    URI[] uris = DistributedCache.getCacheFiles(context  </span><br><span class="line">                .getConfiguration());  </span><br><span class="line">    Path[] paths = DistributedCache.getLocalCacheFiles(context  </span><br><span class="line">                .getConfiguration());  </span><br><span class="line">    <span class="comment">// TODO  </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>而三方库的使用稍微简单，只需要将库上传至hdfs，再用代码添加至classpath即可：</p>
<figure class="highlight openscad"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DistributedCache.addArchiveToClassPath<span class="params">(new Path<span class="params">(<span class="string">"/data/test.jar"</span>)</span>, conf)</span>;</span><br></pre></td></tr></table></figure>
<h3 id="3、symlink的使用">3、symlink的使用</h3><p>Symlink其实就是hdfs文件的一个快捷方式，只需要在路径名后加入#linkname，之后在task中使用linkname即使用相应文件，如下：</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">conf</span>.<span class="keyword">set</span>(<span class="string">"mapred.cache.files"</span>, <span class="string">"/data/data#mData"</span>);</span><br><span class="line"><span class="keyword">conf</span>.<span class="keyword">set</span>(<span class="string">"mapred.cache. archives"</span>, <span class="string">"/data/data.zip#mDataZip"</span>);</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="annotation">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException,  </span><br><span class="line">        InterruptedException </span>&#123;  </span><br><span class="line">    <span class="keyword">super</span>.setup(context);  </span><br><span class="line">    FileReader reader = <span class="keyword">new</span> FileReader(<span class="keyword">new</span> File(<span class="string">"mData"</span>));  </span><br><span class="line">    BufferedReader bReader = <span class="keyword">new</span> BufferedReader(reader);  </span><br><span class="line">    <span class="comment">// TODO  </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在使用symlink之前，需要告知hadoop，如下：</p>
<ul>
<li><a href="/images/2012/02/DistributedCache.html">DistributedCache.createSymlink(Configuration)</a></li>
</ul>
<h3 id="4、注意事项">4、注意事项</h3><ol>
<li>缓存文件（数据、三方库）需上传至HDFS，方能使用；</li>
<li>存较小的情况下，建议将数据全部读入相应节点内存，提高访问速度；</li>
<li>缓存文件是read-only的，不能修改。若要修改得重新输出，将新输出文件作为新缓存进入下一次迭代。</li>
</ol>
</div></article></div></section><footer><div class="paginator"><a href="/2012/02/hadoop-ipc-rpc/" class="prev">上一篇</a><a href="/2012/02/algorithm-search/" class="next">下一篇</a></div><div data-thread-key="2012/02/iterative-mapred-distcache/" data-title="迭代式MapReduce解决方案（二） DistributedCache" data-url="http://hongweiyi.com/2012/02/iterative-mapred-distcache/" data-author-key="1" class="ds-thread"></div><script>var duoshuoQuery = {short_name:"yihongwei"};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
})();

</script></footer><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-66911097-1",'auto');ga('send','pageview');</script><script src="https://cdn.bootcss.com/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>