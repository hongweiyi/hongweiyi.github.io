<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 迭代式MapReduce解决方案（三） · 小e的笔记</title><meta name="description" content="1、前言前面两篇（一）（二）解决方案分别从静态数据（Invariant Data）分离以及分布式缓存来优化迭代式Mapreduce，但是由于Mapreduce天生的缺陷，再加上分布式缓存是分布存放在本地磁盘的，没有一个好的读取方案的话，就会大大提高了每个task的磁盘IO次数。这篇博客算是迭代式Mapreduce的收尾了，来整体分析一下我的解决方案和Haloop方案吧。

2、现存框架的缺陷&amp;amp;我的方案Haloop发布的文献中，说了两个缺陷，再加上董的一个，共仨：
1）动静态数据无法分离，浪费大量资源（磁盘IO，网络带宽，CPU时间），Haloop原文：The first problem is that even"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="stylesheet" href="http://fonts.useso.com/css?family=Source+Sans+Pro:400,600" type="text/css"></head><body><header><a href="/" class="logo-link"><img src="/favicon.png"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="http://weibo.com/1674333040" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="https://twitter.com/hongwei89" target="_blank" class="nav-list-link">TWITTER</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li><li class="nav-list-item"><a href="/tags" target="_self" class="nav-list-link">TAGS</a></li></ul></header><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">迭代式MapReduce解决方案（三）</h1><div class="post-meta"><div class="post-time">Feb 29, 2012</div></div><div class="post-content"><h3 id="1、前言">1、前言</h3><p>前面两篇<a href="http://www.hongweiyi.com/2012/02/mapred-optimize/" target="_blank" rel="external">（一）</a><a href="http://www.hongweiyi.com/2012/02/iterative-mapred-distcache/" target="_blank" rel="external">（二）</a>解决方案分别从静态数据（Invariant Data）分离以及分布式缓存来优化迭代式Mapreduce，但是由于Mapreduce天生的缺陷，再加上分布式缓存是分布存放在本地磁盘的，没有一个好的读取方案的话，就会大大提高了每个task的磁盘IO次数。这篇博客算是迭代式Mapreduce的收尾了，来整体分析一下我的解决方案和Haloop方案吧。</p>
<a id="more"></a>
<h3 id="2、现存框架的缺陷&amp;我的方案">2、现存框架的缺陷&amp;我的方案</h3><p>Haloop发布的文献中，说了两个缺陷，再加上董的一个，共仨：</p>
<p>1）动静态数据无法分离，浪费大量资源（磁盘IO，网络带宽，CPU时间），Haloop原文：The first problem is that even though much of the data may be unchanged from iteration to iteration, the data must be re-loaded and re-processed at each iteration, wasting I/O, network bandwidth, and CPU resources。</p>
<p>我的解决方案：利用分布式缓存来缓存动态数据，可以有效的减少临时数据大小，大量的减少网络带宽压力（10G-&gt;0.25G）。但是，通过我的方案，磁盘IO虽然有所下降，但是仍然有待加强的地方，因磁盘IO主要集中在了map task的read阶段，而在坏的情况下，有可能会从其它node远程读取。Haloop修改了一下这种方式，我待会儿说方法。</p>
<p>2）没有一个客观的停止迭代的标准，Haloop原文：The second problem is that the termination condition may involve detecting when a fixpoint has been reached。</p>
<p>我的解决方案：这个方案没有写成博客，因为觉得太普通了。和大多数应用一样，开启一个新的任务，来计算两次迭代之间的差别，Pagerank计算两次迭代过程之间所有页面PR差之和，SSSP计算所有点的状态。但是需要注意的是，由于一个文件就会开启一个map task，所以需要动脑筋思考一下如何“合并”起来。</p>
<p>3）每次迭代，如果所有task重复重新创建，代价将非常高。怎样重用task以提高效率（task pool）。这个缺陷是<a href="http://dongxicheng.org/mapreduce/iterative-mapreduce-intro/" target="_blank" rel="external">董的博客</a>提出的，这个虽然没有在Haloop中单独提出，但是实现中已经考虑到了。这个在现有框架下，基本是上没可能了，迭代式Mapreduce需要解决的是Job复用的问题，整个task pool就得修改框架了。</p>
<h3 id="3、Haloop解决方案">3、Haloop解决方案</h3><p><img src="/images/2012/02/clip_image0024.jpg" alt="clip_image002"></p>
<p><img src="/images/2012/02/clip_image0043.jpg" alt="clip_image004"></p>
<p>Haloop进行的改进有：</p>
<h4 id="1）提供了一套新的编程接口，以方便用户进行迭代式程序开发">1）提供了一套新的编程接口，以方便用户进行迭代式程序开发</h4><p>Haloop提供了一些有用的方法，如下：</p>
<ul>
<li>SetFixedPointThreshold：设置两次迭代的终止条件，即距离差是否达到某一个阈值</li>
<li>ResultDistance：计算两次距离的方法</li>
<li>setMaxNumOfIterations：设置迭代次数</li>
<li>setIterationInput：设置变化的输入数据</li>
<li>AddInvariantTable：设置不变的输入数据  </li>
</ul>
<p>有了上面的方法，整个迭代式MR过程很清晰，确实提供了很大的方便。</p>
<h4 id="2）_master_node（jobtracker）包含一个循环控制模块，它不断的启动map-reduce计算知道满足迭代终止条件">2） master node（jobtracker）包含一个循环控制模块，它不断的启动map-reduce计算知道满足迭代终止条件</h4><p>从Haloop计算流程图可以看出，Haloop基本实现了job“复用”，只有一个job就可以了，它可以开启多个map/reduce对，而传统的每次迭代过程都需要开启一个job，且一个job只有一个map/reduce对。且迭代终止条件控制在job内部，无需再启新job来计算。</p>
<h4 id="3）设计了新的Task_Scheduler，以便更好的利用data_locality特性">3）设计了新的Task Scheduler，以便更好的利用data locality特性</h4><p>Haloop有一个Loop-aware 任务调度机制。Haloop在首次迭代时会将不变的输入数据保存到相应计算节点上，以后每次调度task，尽量放在固定的那些节点上（locality）。这样，每次迭代，不变的数据就不必重复传输了。</p>
<h4 id="4）数据在各个task_tracker会被缓存（cache）和建索引（index）">4）数据在各个task tracker会被缓存（cache）和建索引（index）</h4><p>Map task的输入与输出，Reduce task的输出都会被建索引和缓存，以加快数据处理速度。这个部分在论文中占的大量份额，所以我也没有仔细看，整体来说就是和分布式缓存有异曲同工之妙。需要说明的是，缓存是指数据被写到本次磁盘，以供下一轮循环迭代时直接使用，Haloop也并没有完全存入内存，应该是担心内存不够使的。</p>
<h3 id="4、总结">4、总结</h3><p>迭代式Mapreduce还有待继续研究，按照董的说法，haloop模型抽象还不够高，支持计算模型有限，而现有的解决方案都不是最优的。我所提出的方案只是在不修改源码的情况下，最大限度的优化计算过程，还是不够优！不过Yahoo!要推出下一代的Mapreduce，从它发表的文章来看，解决迭代式问题好似有戏，可以参考这里：<a href="http://developer.yahoo.com/blogs/hadoop/posts/2011/02/mapreduce-nextgen/" target="_blank" rel="external">The Next Generation of Apache Hadoop MapReduce</a>。</p>
<p> <strong>参考资料</strong><br>&gt;</p>
<blockquote>
<ol>
<li><p>Haloop主页：<a href="http://code.google.com/p/haloop/" target="_blank" rel="external">http://code.google.com/p/haloop/</a></p>
</li>
<li><p>董的博客：<a href="http://dongxicheng.org/mapreduce/iterative-mapreduce-intro/" target="_blank" rel="external">http://dongxicheng.org/mapreduce/iterative-mapreduce-intro/</a></p>
</li>
</ol>
</blockquote>
</div></article></div></section><footer><div class="paginator"><a href="/2012/03/java-boxing/" class="prev">上一篇</a><a href="/2012/02/hadoop-ipc-server/" class="next">下一篇</a></div><div data-thread-key="2012/02/iterative-mapred-summary-haloop/" data-title="迭代式MapReduce解决方案（三）" data-url="http://hongweiyi.com/2012/02/iterative-mapred-summary-haloop/" data-author-key="1" class="ds-thread"></div><script>var duoshuoQuery = {short_name:"yihongwei"};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
})();

</script></footer><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-66911097-1",'auto');ga('send','pageview');</script><script src="https://cdn.bootcss.com/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>