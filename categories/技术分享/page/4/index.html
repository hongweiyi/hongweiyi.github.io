<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 小e的笔记</title><meta name="description" content="A Blog Powered By Hexo"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="stylesheet" href="http://fonts.useso.com/css?family=Source+Sans+Pro:400,600" type="text/css"></head><body><header><a href="/" class="logo-link"><img src="/favicon.png"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="http://weibo.com/1674333040" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="https://twitter.com/hongwei89" target="_blank" class="nav-list-link">TWITTER</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li><li class="nav-list-item"><a href="/tags" target="_self" class="nav-list-link">TAGS</a></li></ul></header><section class="container"><ul class="home post-list"><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2013/01/linux-shell-term-tuning/" class="post-title-link">Shell常用命令 终端优化前篇</a></h2><div class="post-meta"><div class="post-time">Jan 17, 2013</div></div><div class="post-content"></div><a href="2013/01/linux-shell-term-tuning/" class="read-more">... more</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2012/11/zookeeper-ephemeral-nodes-experience/" class="post-title-link">Zookeeper Ephemeral结点使用心得</a></h2><div class="post-meta"><div class="post-time">Nov 5, 2012</div></div><div class="post-content"><p>公司里面在拿Zookeeper做命名服务，通过使用ZK，前端只需要根据指定的ZK地址获得相应的资源或服务的后端服务器地址即可，而后端服务器需要做的仅仅是将自己的地址注册到ZK上作为一个Ephemeral结点即可。（虽然是挺方便后端扩容，但是我个人不太建议直接上ZK，否则开发成本会增加）<br></div><a href="2012/11/zookeeper-ephemeral-nodes-experience/" class="read-more">... more</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2012/10/mapreduce-task-src-analysis/" class="post-title-link">Map/Reduce Task源码分析</a></h2><div class="post-meta"><div class="post-time">Oct 18, 2012</div></div><div class="post-content"><p><strong>一、序言</strong></p>
<p>这篇文章从十一前开始写，陆陆续续看源码并理解其中的原理。主要了解了Map/Reduce的运行流程，并仔细分析了Map流程以及一些细节，但是没有分析仔细Reduce Task，因为和一个朋友@<a href="http://weibo.com/getix2010">lidonghua1990</a>一起分析的，他分析ReduceTask，这篇文章的Reduce的注释部分也是由他添加。等到他分析完Reduce之后，再将链接填上……<br></div><a href="2012/10/mapreduce-task-src-analysis/" class="read-more">... more</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2012/09/mapred-optimize-writable/" class="post-title-link">MapReduce优化（二） —— 善用Writable</a></h2><div class="post-meta"><div class="post-time">Sep 27, 2012</div></div><div class="post-content"><p><strong>一、简述</strong></p>
<p>上文主要是数据压缩的角度来分析了MapReduce压缩临时数据的优化，参见：<a href="http://www.hongweiyi.com/2012/02/mapred-optimize/">MapReduce优化（一）</a>。而这篇会更多的从代码层面说MR任务优化。</p>
<p>MapReduce大多数任务都是做日志分析，而一般的日志分析也就是高级点的WordCount程序：读入一段文本 -&gt; 获取需要的信息 -&gt; 统计输出。<br></div><a href="2012/09/mapred-optimize-writable/" class="read-more">... more</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2012/09/hadoop-bug-in-text/" class="post-title-link">发现Hadoop小bug一枚</a></h2><div class="post-meta"><div class="post-time">Sep 18, 2012</div></div><div class="post-content"><p>最近在做一个任务，合并大小文本文件，每个不到5M，合并之后再进行统计分析。但是统计分析结果不对，本来只有60w个文件，但是最后的结果竟然到了200w了，断断续续debug了几天，从合并、map过程、combine过程、reduce过程，都一一过了一遍。最后发现在map过程中的数据就有重复，而且重复的形式很奇怪。<br></div><a href="2012/09/hadoop-bug-in-text/" class="read-more">... more</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2012/09/apache-hadoop-yarn-background-and-an-overview/" class="post-title-link">Apache Hadoop YARN - 背景及概述</a></h2><div class="post-meta"><div class="post-time">Sep 6, 2012</div></div><div class="post-content"><p>虽然yahoo!关于YARN作为下一代（Next-gen）MapReduce框架的文章（<a href="http://developer.yahoo.com/blogs/hadoop/posts/2011/02/mapreduce-nextgen/">点这里</a>）去年就看过了，但是那个看到是“下一代”，竟然以为只是一个设想，没想到早就发布了版本，导致对于Hadoop的认识还停留在0.20×版本上，真是罪过罪过。由于最近比较忙，闲暇时间扫了扫国内外博客，发现0.23、1.×，以及最近发布的2.×，hadoop的变化非常之大。比如说HDFS Federation（联邦）支持多NameNode并存，也有HA的BackupNode，想多了解的可以看<a href="http://ai-longyu.iteye.com/blog/1566619">这里</a>以及<a href="http://hadoop.apache.org/common/docs/r0.23.0/hadoop-yarn/hadoop-yarn-site/Federation.html">官方文档</a>。最大的莫过于计算框架了，MapReduce进入了2.0时代，MR2.0或者叫YARN（其实YARN和MapReduce没什么关系了），这篇博客就简要的说说Apache Hadoop MapReduce的前世今生吧。主要是翻译了这篇博客：<a href="http://hortonworks.com/blog/apache-hadoop-yarn-background-and-an-overview/">地址</a>，也加上了自己的一些见解，后续再继续添加对YARN的认识。<br></div><a href="2012/09/apache-hadoop-yarn-background-and-an-overview/" class="read-more">... more</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2012/07/the-nosql-ecosystem/" class="post-title-link">转 - NoSQL生态系统</a></h2><div class="post-meta"><div class="post-time">Jul 25, 2012</div></div><div class="post-content"><p>躺在床上看到这篇文章就有一种“垂死病中惊坐起”的感觉。忍不住就给转过来了，顺带附上HTML、PDF以及原版。转载自<a href="http://blog.nosqlfan.com"><strong>NoSQLFan</strong></a>，这网站最贱的一句话就是“<strong>据</strong>说看到好文章不转的人，服务器容易宕机！”，不过虽然贱，但是我喜欢……</p>
<p>［<a href="https://docs.google.com/document/pub?id=1NO__9thOb8V1mM3iQID3IUmwGh9wtra7xkpmvCZIvoU"><strong>HTML**</strong>版**</a>］［<strong><a href="http://blog.nosqlfan.com/wp-content/uploads/2011/nosql_ecosystem.pdf">PDF版</a></strong>］[ <a href="http://www.aosabook.org/en/nosql.html"><strong>原版</strong></a> ] [ <a href="http://blog.nosqlfan.com/html/2171.html"><strong>转载处</strong></a> ]</p></div><a href="2012/07/the-nosql-ecosystem/" class="read-more">... more</a></article></li></ul></section><footer><div class="paginator"><a href="/categories/技术分享/page/3/" class="prev">上一页</a><a href="/categories/技术分享/page/5/" class="next">下一页</a></div></footer><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-66911097-1",'auto');ga('send','pageview');</script><script src="https://cdn.bootcss.com/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>